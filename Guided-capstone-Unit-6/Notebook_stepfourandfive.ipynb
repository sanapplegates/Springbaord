{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pre-Processing and Training Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Science Method\n",
    "\n",
    "1.Problem Identification\n",
    "\n",
    "2.Data Wrangling\n",
    "\n",
    "3.Exploratory Data Analysis\n",
    "\n",
    "4.Pre-processing and Training Data Development\n",
    "\n",
    "* Create dummy or indicator features for categorical variables\n",
    "* Standardize the magnitude of numeric features\n",
    "* Split into testing and training datasets\n",
    "*  Apply scaler to the testing set\n",
    "    \n",
    "5.Modeling\n",
    "\n",
    "* Fit Models with Training Data Set\n",
    "* Review Model Outcomes — Iterate over additional models as needed.\n",
    "* Identify the Final Model\n",
    "\n",
    "6.Documentation\n",
    "* Review the Results\n",
    "* Present and share your findings - storytelling\n",
    "* Finalize Code\n",
    "* Finalize Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanjay\\1Springboard\\Springboard\\Springboard\\Guided-capstone-Unit-6\n",
      "(165, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>triple</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yosemite Ski &amp; Snowboard Area</td>\n",
       "      <td>California</td>\n",
       "      <td>7800</td>\n",
       "      <td>600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>174.873239</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>100.395722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Donner Ski Ranch</td>\n",
       "      <td>California</td>\n",
       "      <td>8012</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>505.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>82.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>100.395722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>June Mountain</td>\n",
       "      <td>California</td>\n",
       "      <td>10090</td>\n",
       "      <td>2590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>174.873239</td>\n",
       "      <td>115.103943</td>\n",
       "      <td>58.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>57.916957</td>\n",
       "      <td>64.16681</td>\n",
       "      <td>128.0</td>\n",
       "      <td>100.395722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name       state  summit_elev  vertical_drop  \\\n",
       "2                Hilltop Ski Area      Alaska         2090            294   \n",
       "4             Sunrise Park Resort     Arizona        11100           1800   \n",
       "5   Yosemite Ski & Snowboard Area  California         7800            600   \n",
       "10               Donner Ski Ranch  California         8012            750   \n",
       "12                  June Mountain  California        10090           2590   \n",
       "\n",
       "    trams  fastEight  fastSixes  fastQuads  quad  triple  ...  \\\n",
       "2     0.0        0.0        0.0          0     0       1  ...   \n",
       "4     0.0        0.0        0.0          1     2       3  ...   \n",
       "5     0.0        0.0        0.0          0     0       1  ...   \n",
       "10    0.0        0.0        0.0          0     0       1  ...   \n",
       "12    0.0        0.0        0.0          2     0       0  ...   \n",
       "\n",
       "    SkiableTerrain_ac  Snow Making_ac  daysOpenLastYear  yearsOpen  \\\n",
       "2                30.0       30.000000        150.000000       36.0   \n",
       "4               800.0       80.000000        115.000000       49.0   \n",
       "5                88.0      174.873239        110.000000       84.0   \n",
       "10              505.0       60.000000        163.000000       82.0   \n",
       "12             1500.0      174.873239        115.103943       58.0   \n",
       "\n",
       "    averageSnowfall  AdultWeekday  AdultWeekend  projectedDaysOpen  \\\n",
       "2              69.0     30.000000      34.00000              152.0   \n",
       "4             250.0     74.000000      78.00000              104.0   \n",
       "5             300.0     47.000000      47.00000              107.0   \n",
       "10            400.0     75.000000      75.00000              170.0   \n",
       "12            250.0     57.916957      64.16681              128.0   \n",
       "\n",
       "    NightSkiing_ac  clusters  \n",
       "2        30.000000         0  \n",
       "4        80.000000         1  \n",
       "5       100.395722         1  \n",
       "10      100.395722         1  \n",
       "12      100.395722         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "df = pd.read_csv('data/step3_output.csv', index_col='Unnamed: 0')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165 entries, 2 to 329\n",
      "Data columns (total 60 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Name                  165 non-null    object \n",
      " 1   summit_elev           165 non-null    int64  \n",
      " 2   vertical_drop         165 non-null    int64  \n",
      " 3   trams                 165 non-null    float64\n",
      " 4   fastEight             165 non-null    float64\n",
      " 5   fastSixes             165 non-null    float64\n",
      " 6   fastQuads             165 non-null    int64  \n",
      " 7   quad                  165 non-null    int64  \n",
      " 8   triple                165 non-null    int64  \n",
      " 9   double                165 non-null    int64  \n",
      " 10  surface               165 non-null    int64  \n",
      " 11  total_chairs          165 non-null    int64  \n",
      " 12  Runs                  165 non-null    float64\n",
      " 13  TerrainParks          165 non-null    float64\n",
      " 14  LongestRun_mi         165 non-null    float64\n",
      " 15  SkiableTerrain_ac     165 non-null    float64\n",
      " 16  Snow Making_ac        165 non-null    float64\n",
      " 17  daysOpenLastYear      165 non-null    float64\n",
      " 18  yearsOpen             165 non-null    float64\n",
      " 19  averageSnowfall       165 non-null    float64\n",
      " 20  AdultWeekday          165 non-null    float64\n",
      " 21  AdultWeekend          165 non-null    float64\n",
      " 22  projectedDaysOpen     165 non-null    float64\n",
      " 23  NightSkiing_ac        165 non-null    float64\n",
      " 24  clusters              165 non-null    int64  \n",
      " 25  state_Alaska          165 non-null    uint8  \n",
      " 26  state_Arizona         165 non-null    uint8  \n",
      " 27  state_California      165 non-null    uint8  \n",
      " 28  state_Colorado        165 non-null    uint8  \n",
      " 29  state_Connecticut     165 non-null    uint8  \n",
      " 30  state_Idaho           165 non-null    uint8  \n",
      " 31  state_Illinois        165 non-null    uint8  \n",
      " 32  state_Indiana         165 non-null    uint8  \n",
      " 33  state_Iowa            165 non-null    uint8  \n",
      " 34  state_Maine           165 non-null    uint8  \n",
      " 35  state_Maryland        165 non-null    uint8  \n",
      " 36  state_Massachusetts   165 non-null    uint8  \n",
      " 37  state_Michigan        165 non-null    uint8  \n",
      " 38  state_Minnesota       165 non-null    uint8  \n",
      " 39  state_Missouri        165 non-null    uint8  \n",
      " 40  state_Montana         165 non-null    uint8  \n",
      " 41  state_Nevada          165 non-null    uint8  \n",
      " 42  state_New Hampshire   165 non-null    uint8  \n",
      " 43  state_New Jersey      165 non-null    uint8  \n",
      " 44  state_New Mexico      165 non-null    uint8  \n",
      " 45  state_New York        165 non-null    uint8  \n",
      " 46  state_North Carolina  165 non-null    uint8  \n",
      " 47  state_Ohio            165 non-null    uint8  \n",
      " 48  state_Oregon          165 non-null    uint8  \n",
      " 49  state_Pennsylvania    165 non-null    uint8  \n",
      " 50  state_Rhode Island    165 non-null    uint8  \n",
      " 51  state_South Dakota    165 non-null    uint8  \n",
      " 52  state_Tennessee       165 non-null    uint8  \n",
      " 53  state_Utah            165 non-null    uint8  \n",
      " 54  state_Vermont         165 non-null    uint8  \n",
      " 55  state_Virginia        165 non-null    uint8  \n",
      " 56  state_Washington      165 non-null    uint8  \n",
      " 57  state_West Virginia   165 non-null    uint8  \n",
      " 58  state_Wisconsin       165 non-null    uint8  \n",
      " 59  state_Wyoming         165 non-null    uint8  \n",
      "dtypes: float64(15), int64(9), object(1), uint8(35)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Create dummy variables for state. Add the dummies back to the dataframe and remove the original column for state.\n",
    "df = pd.concat([df.drop(['state'], axis=1), pd.get_dummies(df[['state']])], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,dfo],axis=1)\n",
    "df=df.drop(['state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165 entries, 2 to 329\n",
      "Data columns (total 60 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Name                  165 non-null    object \n",
      " 1   summit_elev           165 non-null    int64  \n",
      " 2   vertical_drop         165 non-null    int64  \n",
      " 3   trams                 165 non-null    float64\n",
      " 4   fastEight             165 non-null    float64\n",
      " 5   fastSixes             165 non-null    float64\n",
      " 6   fastQuads             165 non-null    int64  \n",
      " 7   quad                  165 non-null    int64  \n",
      " 8   triple                165 non-null    int64  \n",
      " 9   double                165 non-null    int64  \n",
      " 10  surface               165 non-null    int64  \n",
      " 11  total_chairs          165 non-null    int64  \n",
      " 12  Runs                  165 non-null    float64\n",
      " 13  TerrainParks          165 non-null    float64\n",
      " 14  LongestRun_mi         165 non-null    float64\n",
      " 15  SkiableTerrain_ac     165 non-null    float64\n",
      " 16  Snow Making_ac        165 non-null    float64\n",
      " 17  daysOpenLastYear      165 non-null    float64\n",
      " 18  yearsOpen             165 non-null    float64\n",
      " 19  averageSnowfall       165 non-null    float64\n",
      " 20  AdultWeekday          165 non-null    float64\n",
      " 21  AdultWeekend          165 non-null    float64\n",
      " 22  projectedDaysOpen     165 non-null    float64\n",
      " 23  NightSkiing_ac        165 non-null    float64\n",
      " 24  clusters              165 non-null    int64  \n",
      " 25  state_Alaska          165 non-null    float64\n",
      " 26  state_Arizona         165 non-null    float64\n",
      " 27  state_California      165 non-null    float64\n",
      " 28  state_Colorado        165 non-null    float64\n",
      " 29  state_Connecticut     165 non-null    float64\n",
      " 30  state_Idaho           165 non-null    float64\n",
      " 31  state_Illinois        165 non-null    float64\n",
      " 32  state_Indiana         165 non-null    float64\n",
      " 33  state_Iowa            165 non-null    float64\n",
      " 34  state_Maine           165 non-null    float64\n",
      " 35  state_Maryland        165 non-null    float64\n",
      " 36  state_Massachusetts   165 non-null    float64\n",
      " 37  state_Michigan        165 non-null    float64\n",
      " 38  state_Minnesota       165 non-null    float64\n",
      " 39  state_Missouri        165 non-null    float64\n",
      " 40  state_Montana         165 non-null    float64\n",
      " 41  state_Nevada          165 non-null    float64\n",
      " 42  state_New Hampshire   165 non-null    float64\n",
      " 43  state_New Jersey      165 non-null    float64\n",
      " 44  state_New Mexico      165 non-null    float64\n",
      " 45  state_New York        165 non-null    float64\n",
      " 46  state_North Carolina  165 non-null    float64\n",
      " 47  state_Ohio            165 non-null    float64\n",
      " 48  state_Oregon          165 non-null    float64\n",
      " 49  state_Pennsylvania    165 non-null    float64\n",
      " 50  state_Rhode Island    165 non-null    float64\n",
      " 51  state_South Dakota    165 non-null    float64\n",
      " 52  state_Tennessee       165 non-null    float64\n",
      " 53  state_Utah            165 non-null    float64\n",
      " 54  state_Vermont         165 non-null    float64\n",
      " 55  state_Virginia        165 non-null    float64\n",
      " 56  state_Washington      165 non-null    float64\n",
      " 57  state_West Virginia   165 non-null    float64\n",
      " 58  state_Wisconsin       165 non-null    float64\n",
      " 59  state_Wyoming         165 non-null    float64\n",
      "dtypes: float64(50), int64(9), object(1)\n",
      "memory usage: 78.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cols = df.select_dtypes(np.uint8).columns\n",
    "df[cols] = df[cols].astype(float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                    165\n",
       "summit_elev             139\n",
       "vertical_drop           100\n",
       "trams                     1\n",
       "fastEight                 1\n",
       "fastSixes                 1\n",
       "fastQuads                 3\n",
       "quad                      3\n",
       "triple                    6\n",
       "double                    7\n",
       "surface                   7\n",
       "total_chairs             14\n",
       "Runs                     56\n",
       "TerrainParks              5\n",
       "LongestRun_mi            25\n",
       "SkiableTerrain_ac       101\n",
       "Snow Making_ac           71\n",
       "daysOpenLastYear         66\n",
       "yearsOpen                53\n",
       "averageSnowfall          66\n",
       "AdultWeekday             55\n",
       "AdultWeekend             54\n",
       "projectedDaysOpen        54\n",
       "NightSkiing_ac           47\n",
       "clusters                  3\n",
       "state_Alaska              2\n",
       "state_Arizona             2\n",
       "state_California          2\n",
       "state_Colorado            2\n",
       "state_Connecticut         2\n",
       "state_Idaho               2\n",
       "state_Illinois            2\n",
       "state_Indiana             2\n",
       "state_Iowa                2\n",
       "state_Maine               2\n",
       "state_Maryland            2\n",
       "state_Massachusetts       2\n",
       "state_Michigan            2\n",
       "state_Minnesota           2\n",
       "state_Missouri            2\n",
       "state_Montana             2\n",
       "state_Nevada              2\n",
       "state_New Hampshire       2\n",
       "state_New Jersey          2\n",
       "state_New Mexico          2\n",
       "state_New York            2\n",
       "state_North Carolina      2\n",
       "state_Ohio                2\n",
       "state_Oregon              2\n",
       "state_Pennsylvania        2\n",
       "state_Rhode Island        2\n",
       "state_South Dakota        2\n",
       "state_Tennessee           2\n",
       "state_Utah                2\n",
       "state_Vermont             2\n",
       "state_Virginia            2\n",
       "state_Washington          2\n",
       "state_West Virginia       2\n",
       "state_Wisconsin           2\n",
       "state_Wyoming             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the magnitude of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn preprocessing standardize the scale of the features of the dataframe except the name of the resort which we done't need in the dataframe for modeling, so it can be droppped here as well. Also, we want to hold out our response variable(s) so we can have their true values available for model performance review. Let's set <b> AdultWeekend </b> to the y variable as our response for scaling and modeling. Later we will go back and consider the <b> AdultWeekday, dayOpenLastYear, and projectedDaysOpen </b>. For now leave them in the development dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = df.drop(['Name','AdultWeekend', 'trams', 'fastEight', 'fastSixes'], axis=1) # I will also drop 'trams', 'fastEight', 'fastSixes' because they do not have values\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df['AdultWeekend'] \n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled = scaler.transform(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn model selection import train_test_split, and create a 75/25 split with the y = <b>AdultWeekend</b>. We will start by using the adult weekend ticket price as our response variable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start the actual modeling work. First let's fit a multiple linear regression model to predict the `AdultWeekend` price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll build three different models and compare each model's performance. In the end, you'll choose the best model for demonstrating insights to Big Mountain management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science Method\n",
    "\n",
    "1. Problem Identification\n",
    "\n",
    "2. Data Wrangling\n",
    "\n",
    "3. Exploratory Data Analysis\n",
    "\n",
    "4. Pre-processing and Training Data Development\n",
    "\n",
    "5. Modeling\n",
    "    \n",
    "    * Fit Models with Training Data Set\n",
    "    * Review Model Outcomes — Iterate over additional models as needed.\n",
    "    * Identify the Final Model\n",
    "\n",
    "6. Documentation\n",
    "\n",
    "    * Review the Results\n",
    "    * Present and share your findings - storytelling\n",
    "    * Finalize Code\n",
    "    * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models with a Training Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn, fit the model on your training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model 1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the testing dataset and score the model performance with the y_test set and the y-pred values. The explained variance is a measure of the variation explained by the model. This is also known as the R-squared value.\n",
    "\n",
    "Hint: you will have to use the predict() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Model Outcomes — Iterate over additional models as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "\n",
    "var_score = explained_variance_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.631061938546082e+23, 2863585276480.618)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_score,mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the intercept value from the linear model.\n",
    "\n",
    "Hint: our linear regression model lm has an attribute intercept_ for the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-728912615773.5803"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = lm.intercept_\n",
    "intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept is the mean <b>AdultWeekend</b> price for all the resorts given the other characteristics. The addition or subtraction of each of the coefficient values in the regression are numeric adjustments applied to the intercept to provide a particular observation's value for the resulting <b>AdultWeekend</b> value. Also, because we took the time to scale our x values in the training data, we can compare each of the coeeficients for the features to determine the feature importances. Print the coefficient values from the linear model and sort in descending order to identify the top ten most important features.\n",
    "\n",
    "\n",
    "Hint: make sure to review the absolute value of the coefficients, because the adjustment may be positive or negative, but what we are looking for is the magnitude of impact on our response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>4.267946e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>2.442169e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>2.347462e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>2.021485e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New York</th>\n",
       "      <td>1.829169e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Michigan</th>\n",
       "      <td>1.729775e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_New Hampshire</th>\n",
       "      <td>1.500912e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Pennsylvania</th>\n",
       "      <td>1.435702e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <td>1.435702e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_California</th>\n",
       "      <td>1.292389e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Coefficient\n",
       "total_chairs         4.267946e+13\n",
       "surface              2.442169e+13\n",
       "double               2.347462e+13\n",
       "triple               2.021485e+13\n",
       "state_New York       1.829169e+13\n",
       "state_Michigan       1.729775e+13\n",
       "state_New Hampshire  1.500912e+13\n",
       "state_Pennsylvania   1.435702e+13\n",
       "state_Wisconsin      1.435702e+13\n",
       "state_California     1.292389e+13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "coeffs = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "coeffs.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the top ten important features are different states. However, the state is not something the managers at the Big Mountain Resort can do anything about. Given that we care more about actionable traits associated with ticket pricing, rebuild the model without the state features and compare the results.\n",
    "\n",
    "Hint: Try to construct another model using exactly the steps we followed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_columns = df.loc[:, 'state_Alaska':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(states_columns.columns, axis=1) # removing dummies\n",
    "\n",
    "X = df.drop(['Name','AdultWeekend'], axis=1)\n",
    "\n",
    "y = df.AdultWeekend \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "X_scaled=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165 entries, 2 to 329\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   summit_elev        165 non-null    int64  \n",
      " 1   vertical_drop      165 non-null    int64  \n",
      " 2   trams              165 non-null    float64\n",
      " 3   fastEight          165 non-null    float64\n",
      " 4   fastSixes          165 non-null    float64\n",
      " 5   fastQuads          165 non-null    int64  \n",
      " 6   quad               165 non-null    int64  \n",
      " 7   triple             165 non-null    int64  \n",
      " 8   double             165 non-null    int64  \n",
      " 9   surface            165 non-null    int64  \n",
      " 10  total_chairs       165 non-null    int64  \n",
      " 11  Runs               165 non-null    float64\n",
      " 12  TerrainParks       165 non-null    float64\n",
      " 13  LongestRun_mi      165 non-null    float64\n",
      " 14  SkiableTerrain_ac  165 non-null    float64\n",
      " 15  Snow Making_ac     165 non-null    float64\n",
      " 16  daysOpenLastYear   165 non-null    float64\n",
      " 17  yearsOpen          165 non-null    float64\n",
      " 18  averageSnowfall    165 non-null    float64\n",
      " 19  AdultWeekday       165 non-null    float64\n",
      " 20  projectedDaysOpen  165 non-null    float64\n",
      " 21  NightSkiing_ac     165 non-null    float64\n",
      " 22  clusters           165 non-null    int64  \n",
      "dtypes: float64(14), int64(9)\n",
      "memory usage: 30.9 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.618517122635093, 6.552493404471818)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_score2 = explained_variance_score(y_test, y_pred)\n",
    "mae2 = mean_absolute_error(y_test, y_pred)\n",
    "var_score2, mae2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.36835312849733"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept2 = lm.intercept_\n",
    "intercept2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>11.696138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>3.236984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>2.539725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>1.950361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>1.846194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>1.800047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>1.393011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>1.339016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.245524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.926157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "AdultWeekday         11.696138\n",
       "summit_elev           3.236984\n",
       "daysOpenLastYear      2.539725\n",
       "vertical_drop         1.950361\n",
       "clusters              1.846194\n",
       "averageSnowfall       1.800047\n",
       "projectedDaysOpen     1.393011\n",
       "surface               1.339016\n",
       "quad                  1.245524\n",
       "double                0.926157"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs2 = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "coeffs2.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='teal'> When reviewing our new model coefficients, we see `summit_elev` is now in the number two spot. This is also difficult to change from a management prespective and highly correlated with `base_elev` and `vertical_drop`.  This time, rebuild the model without the state features and without the `summit_elev` and without `base_elev`and compare the results. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Name', 'summit_elev', 'AdultWeekend'], axis=1) \n",
    "\n",
    "y = df.AdultWeekend \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "X_scaled=scaler.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5888760458066826, 6.847870429247384)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_score3 = explained_variance_score(y_test, y_pred)\n",
    "mae3 = mean_absolute_error(y_test, y_pred)\n",
    "var_score3, mae3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.37106827594836"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept3 = lm.intercept_\n",
    "intercept3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>11.414365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>2.639338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>2.339447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>2.025792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>1.697329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>1.159907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>1.123829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>1.015996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>0.905010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "AdultWeekday         11.414365\n",
       "averageSnowfall       2.639338\n",
       "vertical_drop         2.339447\n",
       "daysOpenLastYear      2.025792\n",
       "SkiableTerrain_ac     1.697329\n",
       "double                1.159907\n",
       "clusters              1.123829\n",
       "quad                  1.083022\n",
       "surface               1.015996\n",
       "projectedDaysOpen     0.905010"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs3 = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "coeffs3.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the Final Model\n",
    "Review the model performances in the table below and choose the best model for proving insights to Big Mountain management about what features are driving ski resort lift ticket prices. Type your choice in the final markdown cell — you will discuss this selection more in the next step of the guided casptone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Explained Variance| Mean Absolute Error|Features Dropped|\n",
    "| --- | --- | --- | --- |\n",
    "| Model 1.| -0.17841467924139098 0. |8.600786253317091  |-|\n",
    "| Model 2. |0.19761659532526288 0.|7.470076646743068 |'state'|\n",
    "| Model 3. |0.1526587682672247 0. |7.414692188987168 |'state','summit_elev','base_elev'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 because it has less mean absolute error and high explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
